{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/kaggle_titanic/train.csv')\n",
    "df_test = pd.read_csv('data/kaggle_titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcel\\AppData\\Local\\Temp\\ipykernel_28248\\2484296502.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_train_drop['Sex'] = df_train_drop['Sex'].replace({'male':0, 'female':1})\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# DROP passemgerID, name, ticket, cabin\n",
    "df_train_drop = df_train.drop(['PassengerId','Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# ONEHOTENCODE embarked\n",
    "df_train_drop['Embarked'] = df_train_drop['Embarked'].fillna('S')\n",
    "df_embarked = df_train_drop[['Embarked']]\n",
    "embarked_encoder = OneHotEncoder()\n",
    "df_embarked_encoded = pd.DataFrame(data=embarked_encoder.fit_transform(df_embarked).toarray(),\n",
    "                                   columns=embarked_encoder.get_feature_names_out(), \n",
    "                                   index=df_train_drop.index)\n",
    "df_train_drop = df_train_drop.drop(['Embarked'], axis=1)\n",
    "df_train_drop[embarked_encoder.get_feature_names_out()] = df_embarked_encoded\n",
    "\n",
    "\n",
    "# ONEHOTENCODE pclass\n",
    "df_pclass = df_train_drop[['Pclass']]\n",
    "pclass_encoder = OneHotEncoder()\n",
    "df_pclass_encoded = pd.DataFrame(data=pclass_encoder.fit_transform(df_pclass).toarray(),\n",
    "                                   columns=pclass_encoder.get_feature_names_out(), \n",
    "                                   index=df_train_drop.index)\n",
    "df_train_drop = df_train_drop.drop(['Pclass'], axis=1)\n",
    "df_train_drop[pclass_encoder.get_feature_names_out()] = df_pclass_encoded\n",
    "\n",
    "# REPLACE sex\n",
    "df_train_drop['Sex'] = df_train_drop['Sex'].replace({'male':0, 'female':1})\n",
    "\n",
    "# IMPUTE age\n",
    "age_imputer = KNNImputer(n_neighbors=5)\n",
    "df_train_drop['Age'] = age_imputer.fit_transform(df_train_drop[['Age']]).round(1)\n",
    "\n",
    "# SCALE age\n",
    "mean_age = df_train_drop['Age'].mean()**0.5\n",
    "std_age = df_train_drop['Age'].std()**0.5\n",
    "sqrt_transformer = FunctionTransformer(func = lambda x: (x**0.5-mean_age)/std_age, inverse_func=lambda x: (x*std_age+mean_age)**2)\n",
    "df_train_drop[['Age']] = sqrt_transformer.fit_transform(df_train_drop[['Age']]).round(1)\n",
    "\n",
    "# # SCALE SibSp, Parch, Fare\n",
    "# stand_transformer = StandardScaler()\n",
    "# df_train_drop[['SibSp']] = stand_transformer.fit_transform(df_train_drop[['SibSp']])\n",
    "# df_train_drop[['Parch']] = stand_transformer.fit_transform(df_train_drop[['Parch']])\n",
    "# df_train_drop[['Fare']] = stand_transformer.fit_transform(df_train_drop[['Fare']]).round(3)\n",
    "\n",
    "\n",
    "\n",
    "#ToDo:\n",
    "# - scale SibSp, Parch, Fare\n",
    "# - scale age on another way\n",
    "# - use pipeline\n",
    "# - combine SibSp and Parch to family size\n",
    "# - combine other features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: MEAN = 0.81, STD = 0.04\n",
      "RandomForestClassifier: MEAN = 0.82, STD = 0.05\n",
      "GradientBoostingClassifier: MEAN = 0.82, STD = 0.06\n",
      "GradientBoostingClassifier: MEAN = 0.8, STD = 0.05\n"
     ]
    }
   ],
   "source": [
    "## Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df_train_drop.drop(['Survived'], axis=1)\n",
    "y = df_train_drop['Survived']\n",
    "\n",
    "dict_models = {'model_name':[], 'model':[], 'mean':[], 'std':[]}\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(model, X, y, cv=20, scoring='accuracy')\n",
    "print(f'LogisticRegression: MEAN = {scores.mean().round(2)}, STD = {scores.std().round(2)}')\n",
    "dict_models['model_name'].append('LogisticRegression')\n",
    "dict_models['model'].append(model)\n",
    "dict_models['mean'].append(scores.mean())\n",
    "dict_models['std'].append(scores.std())\n",
    "\n",
    "# model_MLP = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=1000, random_state=42, learning_rate_init=0.0001)\n",
    "# scores = cross_val_score(model_MLP, X, y, cv=20, scoring='accuracy')\n",
    "# print(f'MLPClassifier: MEAN = {scores.mean().round(2)}, STD = {scores.std().round(2)}')\n",
    "# df_models = df_models.add({'model_name':'MLPClassifier', 'model': model_MLP, 'mean':scores.mean(), 'std':scores.std()})\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=20, scoring='accuracy')\n",
    "print(f'RandomForestClassifier: MEAN = {scores.mean().round(2)}, STD = {scores.std().round(2)}')\n",
    "dict_models['model_name'].append('RandomForestClassifier')\n",
    "dict_models['model'].append(model)\n",
    "dict_models['mean'].append(scores.mean())\n",
    "dict_models['std'].append(scores.std())\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=20, scoring='accuracy')\n",
    "print(f'GradientBoostingClassifier: MEAN = {scores.mean().round(2)}, STD = {scores.std().round(2)}')\n",
    "dict_models['model_name'].append('GradientBoostingClassifier')\n",
    "dict_models['model'].append(model)\n",
    "dict_models['mean'].append(scores.mean())\n",
    "dict_models['std'].append(scores.std())\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=20, scoring='accuracy')\n",
    "print(f'GradientBoostingClassifier: MEAN = {scores.mean().round(2)}, STD = {scores.std().round(2)}')\n",
    "dict_models['model_name'].append('AdaBoostClassifier')\n",
    "dict_models['model'].append(model)\n",
    "dict_models['mean'].append(scores.mean())\n",
    "dict_models['std'].append(scores.std())\n",
    "\n",
    "df_models = pd.DataFrame(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   model_name  \\\n",
      "1      RandomForestClassifier   \n",
      "2  GradientBoostingClassifier   \n",
      "0          LogisticRegression   \n",
      "3          AdaBoostClassifier   \n",
      "\n",
      "                                               model      mean       std  \n",
      "1  RandomForestClassifier(max_depth=5, random_sta...  0.824848  0.050195  \n",
      "2  GradientBoostingClassifier(max_depth=5, random...  0.822677  0.060789  \n",
      "0                  LogisticRegression(max_iter=1000)  0.807020  0.043130  \n",
      "3  AdaBoostClassifier(n_estimators=100, random_st...  0.803586  0.046666  \n",
      "Best model: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "## Choose and optimize\n",
    "df_models.sort_values(by='mean', ascending=False, inplace=True)\n",
    "print(df_models)\n",
    "best_model = df_models['model_name'][0]\n",
    "print(f'Best model: {best_model}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
